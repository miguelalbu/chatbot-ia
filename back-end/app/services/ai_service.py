from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from app.config.settings import settings
from app.services.sql_service import SQLService
from app.services.rag_service import RAGService
from app.services.memory_service import MemoryService

class AIService:
    def __init__(self):
        if not settings.GOOGLE_API_KEY:
            raise ValueError("API Key do Google n√£o configurada!")
        
        # 1. Configura√ß√£o do LLM via LangChain
        # Usamos temperature=0.7 para ele ser criativo mas n√£o alucinar dados
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=0.7 
        )
        
        # 2. Inje√ß√£o de Depend√™ncias (Seus servi√ßos robustos)
        self.sql_service = SQLService()
        self.rag_service = RAGService()
        self.memory_service = MemoryService()

        # 3. Defini√ß√£o do Prompt Template (Padr√£o LangChain)
        self.prompt_template = PromptTemplate.from_template("""
        Voc√™ √© a assistente virtual especialista da 'Luar Cosm√©ticos'.
        
        >>> INFORMA√á√ïES DE APOIO <<<
        [CAT√ÅLOGO/PRE√áOS - SQL]
        {sql_context}
        
        [MANUAL/REGRAS - RAG]
        {rag_context}
        
        [HIST√ìRICO DA CONVERSA]
        {history}
        
        >>> MENSAGEM ATUAL DO CLIENTE <<<
        {query}
        
        >>> DIRETRIZES DE COMPORTAMENTO E MEM√ìRIA <<<
        
        1. PERSONALIZA√á√ÉO (O PROVA DE MEM√ìRIA):
           - Analise o [HIST√ìRICO DA CONVERSA] atentamente.
           - O cliente j√° disse o nome dele? 
             * SIM: Chame-o pelo nome ocasionalmente (n√£o toda hora) para gerar conex√£o (ex: "Ent√£o, Miguel, veja esta op√ß√£o...").
             * N√ÉO: Se for o in√≠cio da conversa e voc√™ ainda n√£o sabe o nome, ap√≥s responder a d√∫vida dele, pergunte polidamente: "A prop√≥sito, com quem tenho o prazer de falar?".
        
        2. AN√ÅLISE DE CONTINUIDADE:
           - Se J√Å HOUVER conversa no hist√≥rico: N√ÉO USE "Ol√°" ou sauda√ß√µes iniciais novamente. Seja direta.
           - Se for a PRIMEIRA intera√ß√£o (Hist√≥rico vazio): Pode saudar.
        
        3. REGRAS DE NEG√ìCIO:
           - Seja concisa e aja como no WhatsApp (r√°pida e prestativa).
           - PRE√áOS: Use apenas dados do SQL.
           - DICAS: Use apenas dados do RAG.
        """)

        # 4. Cria√ß√£o da Chain (Cadeia de Processamento)
        # Prompt -> LLM -> Texto Puro
        self.chain = self.prompt_template | self.llm | StrOutputParser()

    def generate_response(self, user_query: str, session_id: str = "usuario_padrao") -> str:
        print(f"\n--- [LANGCHAIN] Processando Sess√£o '{session_id}': {user_query} ---")

        # A. Recupera√ß√£o de Contexto (Seus servi√ßos manuais)
        try:
            sql_context = self.sql_service.get_catalog_context()
        except Exception:
            sql_context = "Erro no cat√°logo."

        try:
            rag_context = self.rag_service.search(user_query)
        except Exception:
            rag_context = "Sem dados de base de conhecimento."

        # B. Recupera√ß√£o de Mem√≥ria
        history_tuples = self.memory_service.get_history(session_id)
        history_text = ""
        if history_tuples:
            for role, text in history_tuples[-6:]:
                role_name = "Cliente" if role == "user" else "Vendedor"
                history_text += f"{role_name}: {text}\n"
        else:
            history_text = "In√≠cio da intera√ß√£o."

        # C. Execu√ß√£o da Chain (A m√°gica do LangChain)
        print("üîó [LANGCHAIN] Invocando a Chain...")
        try:
            bot_response = self.chain.invoke({
                "sql_context": sql_context,
                "rag_context": rag_context,
                "history": history_text,
                "query": user_query
            })
            
            # D. Salva na Mem√≥ria
            self.memory_service.add_message(session_id, "user", user_query)
            self.memory_service.add_message(session_id, "model", bot_response)
            
            print("üöÄ [LANGCHAIN] Resposta gerada com sucesso!\n")
            return bot_response

        except Exception as e:
            print(f"‚ùå [ERRO] Falha na Chain: {e}")
            return "Desculpe, tivemos um erro de comunica√ß√£o com nosso sistema central."